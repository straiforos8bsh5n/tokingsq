# 
# Cluster Config
# 
answers: {}
docker_root_dir: /var/lib/docker
enable_cluster_alerting: false
enable_cluster_monitoring: false
enable_network_policy: false
local_cluster_auth_endpoint:
  enabled: true
name: rancher-cluster1
# 
# Rancher Config
# 
rancher_kubernetes_engine_config:
  addon_job_timeout: 30
  authentication:
    strategy: x509|webhook
  authorization: {}
  bastion_host:
    ssh_agent_auth: false
  cloud_provider: {}
  dns:
    linear_autoscaler_params:
      cores_per_replica: 128
      max: 0
      min: 1
      nodes_per_replica: 4
      prevent_single_point_failure: true
    node_selector: null
    nodelocal:
      ip_address: ''
      node_selector: null
      update_strategy:
        rolling_update: {}
    provider: coredns
    reversecidrs: null
    stubdomains: null
    update_strategy:
      rolling_update: {}
    upstreamnameservers:
      - 8.8.8.8
      - 8.8.4.4
  ignore_docker_version: true
# 
# # Currently only nginx ingress provider is supported.
# # To disable ingress controller, set `provider: none`
# # To enable ingress on specific nodes, use the node_selector, eg:
#    provider: nginx
#    node_selector:
#      app: ingress
# 
  ingress:
    provider: none
  kubernetes_version: v1.17.4-rancher1-3
  monitoring:
    provider: none
    replicas: 0
# 
#   If you are using calico on AWS
# 
#    network:
#      plugin: calico
#      calico_network_provider:
#        cloud_provider: aws
# 
# # To specify flannel interface
# 
#    network:
#      plugin: flannel
#      flannel_network_provider:
#      iface: eth1
# 
# # To specify flannel interface for canal plugin
# 
#    network:
#      plugin: canal
#      canal_network_provider:
#        iface: eth1
# 
  network:
    mtu: 0
    plugin: none
  restore:
    restore: false
  rotate_certificates:
    ca_certificates: false
# 
#    services:
#      kube-api:
#        service_cluster_ip_range: 10.43.0.0/16
#      kube-controller:
#        cluster_cidr: 10.42.0.0/16
#        service_cluster_ip_range: 10.43.0.0/16
#      kubelet:
#        cluster_domain: cluster.local
#        cluster_dns_server: 10.43.0.10
# 
  services:
    etcd:
      backup_config:
        enabled: true
        interval_hours: 12
        retention: 6
        safe_timestamp: false
      creation: 12h
      extra_args:
        auto-compaction-retention: '240'
        election-timeout: '5000'
        heartbeat-interval: '500'
        quota-backend-bytes: '6442450944'
      gid: 0
      retention: 72h
      snapshot: false
      uid: 0
    kube-api:
      always_pull_images: false
      extra_args:
        default-watch-cache-size: '1500'
        delete-collection-workers: '3'
        event-ttl: 24h0m0s
        kubelet-timeout: 10s
        max-mutating-requests-inflight: '400'
        max-requests-inflight: '3200'
        v: '2'
        watch-cache: 'true'
      pod_security_policy: false
      service_cluster_ip_range: 10.43.0.0/16
      service_node_port_range: 30000-32767
    kube-controller:
      cluster_cidr: 10.42.0.0/16
      extra_args:
        concurrent-deployment-syncs: '5'
        concurrent-endpoint-syncs: '5'
        concurrent-gc-syncs: '20'
        concurrent-namespace-syncs: '10'
        concurrent-replicaset-syncs: '5'
        concurrent-service-syncs: '4'
        concurrent-serviceaccount-token-syncs: '5'
        deployment-controller-sync-period: 30s
        feature-gates: TaintBasedEvictions=false
        node-cidr-mask-size: '24'
        node-monitor-grace-period: 20s
        node-monitor-period: 5s
        node-startup-grace-period: 30s
        pod-eviction-timeout: 1m
        pvclaimbinder-sync-period: 15s
        v: '2'
      service_cluster_ip_range: 10.43.0.0/16
    kubelet:
      cluster_dns_server: 10.43.0.10
      cluster_domain: cluster1.local
      extra_args:
        allowed-unsafe-sysctls: net.*
        cgroup-driver: cgroupfs
        cgroups-per-qos: 'true'
        enforce-node-allocatable: pods
        event-qps: '0'
        eviction-hard: >-
          memory.available<300Mi,nodefs.available<10%,imagefs.available<15%,nodefs.inodesFree<5%
        eviction-max-pod-grace-period: '30'
        eviction-pressure-transition-period: 30s
        eviction-soft-grace-period: memory.available=1m30s
        global-housekeeping-interval: 1m0s
        housekeeping-interval: 10s
        image-pull-progress-deadline: 1h
        kube-api-burst: '30'
        kube-api-qps: '15'
        kube-reserved: 'cpu=0.25,memory=512Mi'
        max-open-files: '2000000'
        max-pods: '250'
        network-plugin-mtu: '0'
        node-status-update-frequency: 20s
        protect-kernel-defaults: 'false'
        registry-burst: '10'
        registry-qps: '0'
        runtime-request-timeout: 2m0s
        serialize-image-pulls: 'false'
        streaming-connection-idle-timeout: 1800s
        sync-frequency: 10s
        system-reserved: 'cpu=0.25,memory=200Mi'
        v: '2'
        volume-stats-agg-period: 1m0s
      fail_swap_on: false
      generate_serving_certificate: false
    kubeproxy:
      extra_args:
        conntrack-max-per-core: '262144'
        conntrack-min: '1048576'
        conntrack-tcp-timeout-close-wait: 30s
        conntrack-tcp-timeout-established: 120s
        ipvs-min-sync-period: 10s
        ipvs-sync-period: 30s
        kube-api-burst: '20'
        kube-api-qps: '10'
        proxy-mode: ipvs
        v: '2'
      image: 'slpcat/hyperkube:v1.17.3'
    scheduler: {}
  ssh_agent_auth: false
  upgrade_strategy:
    drain: false
    max_unavailable_controlplane: '1'
    max_unavailable_worker: 10%
    node_drain_input:
      delete_local_data: 'false'
      force: false
      grace_period: -1
      ignore_daemon_sets: true
      timeout: 120
scheduled_cluster_scan:
  enabled: false
  scan_config:
    cis_scan_config:
      debug_master: false
      debug_worker: false
      override_benchmark_version: rke-cis-1.4
      profile: permissive
  schedule_config:
    cron_schedule: 0 0 * * *
    retention: 24

