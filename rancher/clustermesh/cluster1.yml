# 
# Cluster Config
# 
answers: {}
docker_root_dir: /var/lib/docker
enable_cluster_alerting: false
enable_cluster_monitoring: false
enable_network_policy: false
local_cluster_auth_endpoint:
  enabled: true
name: cluster1
# 
# Rancher Config
# 
rancher_kubernetes_engine_config:
  addon_job_timeout: 30
  authentication:
    strategy: x509|webhook
  authorization: {}
  bastion_host:
    ssh_agent_auth: false
  dns:
    provider: coredns
    upstreamnameservers:
      - 8.8.8.8
      - 8.8.4.4
  cloud_provider: {}
  ignore_docker_version: true
# 
# # Currently only nginx ingress provider is supported.
# # To disable ingress controller, set `provider: none`
# # To enable ingress on specific nodes, use the node_selector, eg:
#    provider: nginx
#    node_selector:
#      app: ingress
# 
  ingress:
    provider: none
  kubernetes_version: v1.17.3-rancher1-1
  monitoring:
    provider: metrics-server
# 
#   If you are using calico on AWS
# 
#    network:
#      plugin: calico
#      calico_network_provider:
#        cloud_provider: aws
# 
# # To specify flannel interface
# 
#    network:
#      plugin: flannel
#      flannel_network_provider:
#      iface: eth1
# 
# # To specify flannel interface for canal plugin
# 
#    network:
#      plugin: canal
#      canal_network_provider:
#        iface: eth1
# 
  network:
    mtu: 0
    plugin: none
  restore:
    restore: false
# 
#    services:
#      kube-api:
#        service_cluster_ip_range: 10.43.0.0/16
#      kube-controller:
#        cluster_cidr: 10.42.0.0/16
#        service_cluster_ip_range: 10.43.0.0/16
#      kubelet:
#        cluster_domain: cluster.local
#        cluster_dns_server: 10.43.0.10
# 
  system_images:
    kubernetes: slpcat/hyperkube:v1.17.3
    #etcd: rancher/coreos-etcd:v3.1.12
    #alpine: rancher/rke-tools:v0.1.9
    #nginx_proxy: rancher/rke-tools:v0.1.9
    #cert_downloader: rancher/rke-tools:v0.1.9
    #kubernetes_services_sidecar: rancher/rke-tools:v0.1.9
    #kubedns: rancher/k8s-dns-kube-dns-amd64:1.14.8
    #dnsmasq: rancher/k8s-dns-dnsmasq-nanny-amd64:1.14.8
    #kubedns_sidecar: rancher/k8s-dns-sidecar-amd64:1.14.8
    #kubedns_autoscaler: rancher/cluster-proportional-autoscaler-amd64:1.0.0
    pod_infra_container: rancher/pause-amd64:3.1
  services:
    etcd:
      backup_config:
        enabled: true
        interval_hours: 12
        retention: 6
        safe_timestamp: false
      creation: 12h
      extra_args:
        auto-compaction-retention: '240'
        election-timeout: '5000'
        heartbeat-interval: '500'
        quota-backend-bytes: '6442450944'
      gid: 0
      retention: 72h
      snapshot: false
      uid: 0
    kube-api:
      always_pull_images: false
      extra_args:
        default-watch-cache-size: '1500'
        event-ttl: 24h0m0s
        kubelet-timeout: 10s
        max-mutating-requests-inflight: '400'
        max-requests-inflight: '3200'
        watch-cache: 'true'
        delete-collection-workers: '3'
        v: '2'
      pod_security_policy: false
      service_cluster_ip_range: 10.43.0.0/16
      service_node_port_range: 30000-32767
    kube-controller:
      cluster_cidr: 10.42.0.0/16
      service_cluster_ip_range: 10.43.0.0/16
      extra_args:
        concurrent-deployment-syncs: '5'
        concurrent-endpoint-syncs: '5'
        concurrent-gc-syncs: '20'
        concurrent-namespace-syncs: '10'
        concurrent-replicaset-syncs: '5'
        concurrent-service-syncs: '4'
        concurrent-serviceaccount-token-syncs: '5'
        deployment-controller-sync-period: 30s
        feature-gates: TaintBasedEvictions=false
        node-cidr-mask-size: '24'
        node-monitor-grace-period: 20s
        node-monitor-period: 5s
        node-startup-grace-period: 30s
        pod-eviction-timeout: 1m
        pvclaimbinder-sync-period: 15s
        v: '2'
    kubelet:
      cluster_dns_server: 10.43.0.10
      cluster_domain: cluster1.local
      extra_args:
        allowed-unsafe-sysctls: net.*
        cgroup-driver: cgroupfs
        cgroups-per-qos: 'true'
        enforce-node-allocatable: pods
        event-qps: '0'
        eviction-hard: >-
          memory.available<300Mi,nodefs.available<10%,imagefs.available<15%,nodefs.inodesFree<5%
        eviction-max-pod-grace-period: '30'
        eviction-pressure-transition-period: 30s
        eviction-soft-grace-period: memory.available=1m30s
        global-housekeeping-interval: 1m0s
        housekeeping-interval: 10s
        image-pull-progress-deadline: 1h
        kube-api-burst: '30'
        kube-api-qps: '15'
        kube-reserved: 'cpu=0.25,memory=512Mi'
        #make-iptables-util-chains: 'true'
        max-open-files: '2000000'
        max-pods: '250'
        network-plugin-mtu: '0'
        node-status-update-frequency: 20s
        protect-kernel-defaults: 'false'
        registry-burst: '10'
        registry-qps: '0'
        runtime-request-timeout: 2m0s
        serialize-image-pulls: 'false'
        streaming-connection-idle-timeout: 1800s
        sync-frequency: 10s
        system-reserved: 'cpu=0.25,memory=200Mi'
        v: '2'
        volume-stats-agg-period: 1m0s
      fail_swap_on: false
      generate_serving_certificate: false
    kubeproxy:
      image: 'slpcat/hyperkube:v1.17.3'
      extra_args:
        conntrack-max-per-core: '262144'
        conntrack-min: '1048576'
        conntrack-tcp-timeout-close-wait: '30s'
        conntrack-tcp-timeout-established: '120s'
        ipvs-min-sync-period: 10s
        ipvs-sync-period: 30s
        kube-api-burst: '20'
        kube-api-qps: '10'
        proxy-mode: ipvs
        v: '2'
    scheduler: {}
  ssh_agent_auth: false

